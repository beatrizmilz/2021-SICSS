
<!-- README.md is generated from README.Rmd. Please edit that file -->

# Day 2: Collecting Digital Trace Data

## Pre-arrival

-   Materiais dispon√≠veis em: <https://sicss.io/curriculum>

### What is Digital Trace Data?

-   ‚ÄúPegadas digitais‚Äù. Novas possibilidades de acompanhar/estudar o
    comportamento humano em maior escala. Enquanto interagimos com a
    tecnologia, estamos deixando rastros digitais" do nosso
    comportamento.

-   Mostrou um exemplo de estudo: Eagle et al.¬†2010. O que podemos
    aprender com os dados? No estudo mostrado, a diversidade da rede de
    contatos das pessoas e as pessoas que elas conectavam nas redes
    sociais foram relacionadas com desigualdade econ√¥mica e diversidade.

-   Dados de celular! Onde as pessoas est√£o? Est√£o em casa? Relacionado
    com COVID-19: no futuro (talvez pr√≥ximo) poderemos saber se as
    pessoas est√£o respeitando a quarentena (ou outras regras).

-   Digital trace data: s√£o grandes bases de dados digitais, que
    permitem estudar o comportamento humano em uma escala jamais vista.
    Exemplo: redes sociais, dados de pesquisa na internet, blogs, dados
    geo-espaciais, audio-visual, arquivos hist√≥ricos, registros
    administrativos. Qualquer tipo de pegada digital que deixamos! Esses
    dados nos permitem viajar no tempo, √© poss√≠vel acessar uma p√°gina da
    internet no passado.

-   Esses dados raramente s√£o ‚Äúperfeitos‚Äù. Falamos anteriormente que em
    CS separamos os dados ‚Äúcustom-made‚Äù e os dados ‚Äúready-made‚Äù (falado
    anteriormente na [aula
    1-1](https://github.com/beatrizmilz/2021-SICSS/blob/master/notes/Day_1-Introduction_and_Ethics/README.md#introduction-to-computational-social-science)).
    Nesse caso, os dados que usamos aqui s√£o mais ‚Äúready-made‚Äù: s√£o
    dados criados com um objetivo, e usamos esses dados com outros
    objetivos.

### Strengths and Weakness of Digital Trace Data

-   ‚ÄúFor√ßas‚Äù da Digital trace data:

    -   Big: tem mais dados, e dados muito grandes! Avan√ßos em poder
        computacional tamb√©m permite que a gente consiga
        coletar/analisar esses dados.

    -   Always on: sempre dispon√≠vel. Exemplo: redes sociais apresentam
        um registro do que est√° acontecendo on-line.

    -   Non-reactive: n√£o resulta de uma intera√ß√£o onde a pessoa
        pesquisadora pergunta a opini√£o de uma pessoa que est√°
        participando do estudo (ex. entrevista, survey, grupo focal,
        etc). Isso √© bem relevante quando se trata de pesquisas onde as
        perguntas feitas na entrevista/survey/grupo focal s√£o de temas
        que possam constranger as pessoas participantes, e que elas n√£o
        queiram responder.

    -   Capture social relationships: conseguimos dados das redes
        sociais.

-   ‚ÄúFraquezas‚Äù da Digital trace data:

    -   Inaccessible: muito dos dados (e muitos dados valiosos para
        entender o comportamento humano) atualmente √© inacess√≠vel, pois
        est√£o na posse de grandes empresas (como Google, Apple, Amazon,
        etc). Muitas vezes elas n√£o podem disponibilizar essas bases de
        dados por quest√µes legais.

    -   Non-representative: os dados n√£o representam a popula√ß√£o
        inteira. Pensando em redes sociais: % de pessoas da popula√ß√£o
        que usa essa rede, pensar na presen√ßa grupos em termos de idade,
        sexo, urbano/rural, grupos minorit√°rios, etc. Se queremos
        estudar dados de, por exemplo, twitter, precisamos estar cientes
        dessas vieses. E essas porcentagens da popula√ß√£o nas redes
        sociais muda ao longo do tempo, e entre as plataformas. E se os
        dados conter vieses (bias), e n√£o reflete fielmente a popula√ß√£o
        que estamos tentando estudar?

    -   Drifting: as plataformas usadas mudam com o tempo, as pessoas
        migram de redes sociais (ex: myspace -&gt; facebook). A rela√ß√£o
        entre as pessoas e as plataformas usadas tamb√©m muda com o
        tempo. Ent√£o precisamos ter aten√ß√£o √† isso: se queremos estudar
        um intervalo de tempo, pensar em quais plataformas eram usadas
        nesse per√≠odo (e por quem).

    -   Algorithimically confounded: situa√ß√£o onde um algoritmo dentro
        de uma plataforma digital √© alterado, e isso cria uma mudan√ßa no
        que vemos de comportamento humano. Interpretamos essa mudan√ßa
        como algo significativo, por√©m pode ser apenas a forma como as
        pessoas est√£o interagindo com o algoritmo. A caixa preta de ML:
        em alguns casos, n√£o sabemos o que est√° causando algo.

    -   Unstructured: os dados s√£o bagun√ßados e n√£o estruturados! A
        maior parte do tempo das pessoas que trabalham com ci√™ncia de
        dados √© usada limpando e arrumando dados!

    -   Sensitive: muitas pegadas digitais s√£o informa√ß√µes privadas e
        sens√≠veis. Ex: dados de redes de relacionamento (ok cupid).

    -   Incomplete: os dados podem estar incompletos. Em alguns casos
        est√° relacionado as regras da plataforma usada para coletar os
        dados.

    -   Elite/publication bias: teremos uma fotografia distorcida da
        realidade. Em alguns casos, as informa√ß√µes encontradas s√£o a
        vis√£o de pessoas em situa√ß√£o privilegiada (ex comum em
        documentos hist√≥ricos). Ex nas redes sociais: as pessoas est√£o
        postando coisas para fazer com que elas tenham mais status (look
        better).

    -   Positivity-bias: Nas redes sociais, as pessoas postam mais
        coisas positivas, e n√£o postam tanto as coisas negativas.

-   O futuro do digital trace data: temos que encontrar formas de nos
    aproveitar das for√ßas do DTD, ao mesmo tempo reconhecer as fraquezas
    de DTD (e lidar com isso). As melhores pesquisas futuras em CSC
    ser√£o h√≠bridas: usando dados ready-made e custom-made.

### Application Programming Interfaces (API)

-   O que √© uma API?

    -   √â uma das principais ferramentas usadas na CSC que quer estudar
        digital trace data.

    -   Possibilita coletar dados de algumas redes sociais, mas n√£o
        apenas!

    -   A API possibilita alguns grupos de pessoas a acessarem alguns
        tipos de dados. Os dados dispon√≠veis pode depender devido √†s
        credenciais (credentials).

    -   Muitas APIs n√£o s√£o p√∫blicas: existem dentro de uma empresa, ou
        entre duas companhias para transmitir dados.

    -   O n√∫mero de APIs est√° crescendo! Pesquisar por APIs

        -   [Programmable
            Web](https://www.programmableweb.com/category/all/apis)
        -   [Any API](https://any-api.com/)

-   Como uma API funciona?

    -   Para criar a URL para buscar dados em uma API: Base API URL +
        Requested Filds/Data (endpoints) + Data format requested
        (usually JSON) + Query + API Key (credential/token)

    -   JSON √© uma forma eficiente para armazenar dados, e √© muito usado
        em API

    -   Para usar a API, lemos a documenta√ß√£o para descobrir como criar
        as URLs que devemos usar. A documenta√ß√£o √© um manual.

    -   API credential/access token: algumas APIs n√£o pedem credenciais.

    -   Rate limiting: uma API tem regras sobre a quantidade de dados
        que √© permitido coletar em um intervalo determinado de tempo.
        Entender isso, e se necess√°rio, colocar pausas no c√≥digo.
        Throttling: o site mostra que est√° perto de atingir o rate limit
        e retorna os dados cada vez mais devagar.

    -   Exemplo com twitter: buscar dados na API do twitter. Usar no
        maximo n = 18 mil. Essa busca com a API simples s√≥ busca os
        dados recentes. O argumento `retryonratelimit` da fun√ß√£o
        `rtweet::search_tweets()` √© √∫til nesse caso.

-   Autenticando:

``` r
# install.packages("rtweet")
library(magrittr, include.only = "%>%")

# A forma de realizar a autentica√ß√£o mostrada no video 
# estava gerando um erro. Nas issues do pacote, encontrei
# outras pessoas com o mesmo erro. Uma das sugest√µes que
# encontrei por l√° √© essa fun√ß√£o bearer_token(), 
# que funcionou bem :)

rtweet::bearer_token()
```

-   Buscando os tweets

``` r
# Fiz a pesquisa com outro termo..
tweets <- rtweet::search_tweets(
  q = "rstats", # query para buscar
  n = 4000,  # n√∫mero de tweets para coletar
  include_rts = FALSE # queremos os RTs ou n√£o?
  )

# salvei o resultado pra nao precisar ficar coletando
# sempre que eu executar esse c√≥digo (√© demorado)

readr::write_rds(tweets, file = "exemplo_tweets.Rds")
```

``` r
# abrindo os tweets salvos
tweets_salvos <- readr::read_rds("exemplo_tweets.Rds")

# carregando apenas o pipe:
library(magrittr, include.only = "%>%") 

# n√£o quero ver a base toda, tem muitas colunas!
tweets_salvos %>% 
  dplyr::select(created_at, screen_name, text) 
#> # A tibble: 4,000 x 3
#>    created_at          screen_name   text                                       
#>    <dttm>              <chr>         <chr>                                      
#>  1 2021-05-11 12:55:22 theRcast      "A great surprise to start the ‚òÄÔ∏è : My abst‚Ä¶
#>  2 2021-05-11 12:52:10 theRcast      "A great surprise to start the ‚òÄÔ∏è: My abstr‚Ä¶
#>  3 2021-05-08 12:52:09 theRcast      "@moriah_taylor58 That's great! We are sta‚Ä¶
#>  4 2021-05-11 10:56:57 theRcast      "My week of ‚úçÔ∏è ‚ûïüéô for #rstats @rweekly_org ‚Ä¶
#>  5 2021-05-05 13:27:17 theRcast      "@cantabile {renv} is the easiest path to ‚Ä¶
#>  6 2021-05-07 12:51:36 vsni          "Our free tool ASRgenomics offers molecula‚Ä¶
#>  7 2021-05-11 12:45:56 vsni          "ASRgenomics facilitates the generation of‚Ä¶
#>  8 2021-05-07 12:53:39 ASreml        "Our free tool ASRgenomics offers molecula‚Ä¶
#>  9 2021-05-11 12:43:45 ASreml        "ASRgenomics facilitates the generation of‚Ä¶
#> 10 2021-05-08 18:41:00 SourabhSKato‚Ä¶ "Learn Practical Text Classification With ‚Ä¶
#> # ‚Ä¶ with 3,990 more rows
```

-   Quais s√£o as colunas presentes?

``` r
names(tweets_salvos)
#>  [1] "user_id"                 "status_id"              
#>  [3] "created_at"              "screen_name"            
#>  [5] "text"                    "source"                 
#>  [7] "display_text_width"      "reply_to_status_id"     
#>  [9] "reply_to_user_id"        "reply_to_screen_name"   
#> [11] "is_quote"                "is_retweet"             
#> [13] "favorite_count"          "retweet_count"          
#> [15] "quote_count"             "reply_count"            
#> [17] "hashtags"                "symbols"                
#> [19] "urls_url"                "urls_t.co"              
#> [21] "urls_expanded_url"       "media_url"              
#> [23] "media_t.co"              "media_expanded_url"     
#> [25] "media_type"              "ext_media_url"          
#> [27] "ext_media_t.co"          "ext_media_expanded_url" 
#> [29] "ext_media_type"          "mentions_user_id"       
#> [31] "mentions_screen_name"    "lang"                   
#> [33] "quoted_status_id"        "quoted_text"            
#> [35] "quoted_created_at"       "quoted_source"          
#> [37] "quoted_favorite_count"   "quoted_retweet_count"   
#> [39] "quoted_user_id"          "quoted_screen_name"     
#> [41] "quoted_name"             "quoted_followers_count" 
#> [43] "quoted_friends_count"    "quoted_statuses_count"  
#> [45] "quoted_location"         "quoted_description"     
#> [47] "quoted_verified"         "retweet_status_id"      
#> [49] "retweet_text"            "retweet_created_at"     
#> [51] "retweet_source"          "retweet_favorite_count" 
#> [53] "retweet_retweet_count"   "retweet_user_id"        
#> [55] "retweet_screen_name"     "retweet_name"           
#> [57] "retweet_followers_count" "retweet_friends_count"  
#> [59] "retweet_statuses_count"  "retweet_location"       
#> [61] "retweet_description"     "retweet_verified"       
#> [63] "place_url"               "place_name"             
#> [65] "place_full_name"         "place_type"             
#> [67] "country"                 "country_code"           
#> [69] "geo_coords"              "coords_coords"          
#> [71] "bbox_coords"             "status_url"             
#> [73] "name"                    "location"               
#> [75] "description"             "url"                    
#> [77] "protected"               "followers_count"        
#> [79] "friends_count"           "listed_count"           
#> [81] "statuses_count"          "favourites_count"       
#> [83] "account_created_at"      "verified"               
#> [85] "profile_url"             "profile_expanded_url"   
#> [87] "account_lang"            "profile_banner_url"     
#> [89] "profile_background_url"  "profile_image_url"
```

-   Criar um gr√°fico

``` r
dia_min <- format(min(tweets_salvos$created_at), "%d/%m")
dia_max <- format(max(tweets_salvos$created_at), "%d/%m")

tweets_salvos %>% 
  rtweet::ts_plot(by = "hours") +
  ggplot2::theme_minimal() + 
  ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
  ggplot2::labs(x = "Data", y = "N√∫mero de tweets",
                title = glue::glue("Frequ√™ncia de tweets sobre rstats, entre os dias {dia_min} e {dia_max}"),
                subtitle = "Contagem de tweets agregado por hora",
                caption = "\nFonte: Dados coletados da API do Twitter, atrav√©s do pacote {rtweet}.")
```

<img src="README_files/figure-gfm/unnamed-chunk-6-1.png" style="display: block; margin: auto;" />

-   Ver os tweets em uma regi√£o (EUA)

``` r
geo_tweets <- rtweet::search_tweets(
  q = "rstats", # query para buscar
  n = 4000,  # n√∫mero de tweets para coletar
  include_rts = FALSE, # queremos os RTs ou n√£o?
  geocode = rtweet::lookup_coords("usa"),
  type = "recent"
  )

# salvei o resultado pra nao precisar ficar coletando
# sempre que eu executar esse c√≥digo (√© demorado)

readr::write_rds(geo_tweets, file = "exemplo_geo_tweets.Rds")
```

``` r
# abrindo os tweets salvos
tweets_geo_salvos <- readr::read_rds("exemplo_geo_tweets.Rds")

# arrumando as colunas lat long
geocoded <- rtweet::lat_lng(tweets_geo_salvos)
```

``` r
# plotando o mapa com o pacote maps
par(mar = c(0, 0, 0, 0))
maps::map("world", lwd = .25)
with(geocoded, points(
  lng,
  lat,
  pch = 20,
  cex = .50,
  col = rgb(0, .3, .7, .75)
))
```

<img src="README_files/figure-gfm/unnamed-chunk-9-1.png" style="display: block; margin: auto;" />

``` r
world <-
  rnaturalearth::ne_countries(scale = "medium", returnclass = "sf")

sf_usa <-
  world %>% dplyr::filter(admin == "United States of America")

geocoded_filtrado_sf <- geocoded %>%
  tidyr::drop_na(lat, lng) %>%
  sf::st_as_sf(coords = c("lng", "lat"), crs = 4326)

dia_min <- format(min(geocoded_filtrado_sf$created_at), "%d/%m")
dia_max <- format(max(geocoded_filtrado_sf$created_at), "%d/%m")


  geocoded_filtrado_sf %>% 
  ggplot2::ggplot() +
  ggplot2::geom_sf(data = sf_usa) +
  ggplot2::geom_sf(color = rgb(0, .3, .7, .75)) +
  ggplot2::theme_bw() +
  ggplot2::coord_sf(xlim = c(-127, -65),
                    ylim = c(23, 51),
                    expand = FALSE) +
  ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
  ggplot2::labs(
    x = "Longitude",
    y = "Latitude",
    title = glue::glue(
      "Tweets sobre rstats entre os dias {dia_min} e {dia_max}"
    ),
    subtitle = "Tweets que informaram a localiza√ß√£o, e postados nos EUA",
    caption = "\nFonte: Dados coletados da API do Twitter, atrav√©s do pacote {rtweet}."
  )
```

<img src="README_files/figure-gfm/unnamed-chunk-10-1.png" style="display: block; margin: auto;" />

-   No exemplo, mostrou mais coisas que podemos fazer com o pacote
    rtweet.

-   Fun√ß√£o pra checar o rate limit:

``` r
head(rtweet::rate_limit()[50:55, 1:4])
#> # A tibble: 6 x 4
#>   query                                             limit remaining reset       
#>   <chr>                                             <int>     <int> <drtn>      
#> 1 users/by/username/:source_username/following&POST    50        50 15.02709 mi‚Ä¶
#> 2 users/:id/followers                                  15        15 15.02709 mi‚Ä¶
#> 3 users/suggestions/:slug/members                      15        15 15.02709 mi‚Ä¶
#> 4 users/:id/following                                  15        15 15.02709 mi‚Ä¶
#> 5 users/:id/mentions                                  180       180 15.02709 mi‚Ä¶
#> 6 users/by/username/:username                         900       900 15.02709 mi‚Ä¶
```

-   Postar tweets: `rtweet::post_tweet()`

-   Podemos fazer um loop para repetir a busca :)

-   APIs podem ser usadas n√£o apenas para coletar dados, mas tamb√©m para
    visualiza√ß√£o/an√°lise/modelagem

-   Desafios ao trabalhar com APIs:

    -   Muitos dados ainda n√£o est√£o dispon√≠veis publicamente.

    -   Cada API tem seus padr√µes, ent√£o aprender a usar uma API
        significa que precisamos ler com cuidado a documenta√ß√£o.

-   O final do video est√° repetido.

### Screen Scraping

Previsto 13/05

### Building Apps and Bots for Social Science Research

Previsto 14/05
